"""Создайте новый проект Scrapy.Дайте ему подходящее имя и убедитесь,
что ваше окружение правильно настроено для работы с проектом.

Создайте нового паука, способного перемещаться по сайту www.unsplash.com.
Ваш паук должен уметь перемещаться по категориям фотографий и получать доступ к страницам отдельных фотографий.
Определите элемент (Item) в Scrapy, который будет представлять изображение. Ваш элемент должен включать такие детали, как URL изображения, название изображения и категорию, к которой оно принадлежит.
Используйте Scrapy ImagesPipeline для загрузки изображений. Обязательно установите параметр IMAGES_STORE в файле settings.py. Убедитесь, что ваш паук правильно выдает элементы изображений, которые может обработать ImagesPipeline.
Сохраните дополнительные сведения об изображениях (название, категория) в CSV-файле. Каждая строка должна соответствовать одному изображению и содержать URL изображения, локальный путь к файлу (после загрузки), название и категорию."""

from pymongo import MongoClient
import json

client = MongoClient('localhost', 27017)
db = client['books24']
books = db.books_24

with open('./bookparser/book24.json', 'r') as f:
    data = json.load(f)
count = 0
bad_count = 0

for book in data:
    try:
        books.insert_one(book)
        count += 1
        print(f'Добавлено {count} данных')
    except:
        print(book)
        bad_count += 1
client.close()

print(f'Не добавлено {bad_count} данных')
